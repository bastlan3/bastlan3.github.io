<!DOCTYPE html>
<html>
<head>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
            font-family: 'Arial', sans-serif;
        }
        body {
            background-color: #f7f7f7;
        }
        .poster {
            width: 100%;
            background-color: white;
            display: grid;
            grid-template-columns: 1fr 1fr;
            grid-template-rows: auto auto auto auto auto;
            grid-template-areas:
                "header header"
                "intro intro"
                "methods methods"
                "results1 results2"
                "frequency frequency"
                "conclusion conclusion";
            grid-gap: 20px;
            padding: 30px;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);
        }
        .section {
            background-color: #ffffff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
        }
        .header {
            grid-area: header;
            background: linear-gradient(135deg, #2c3e50, #4a69bd);
            color: white;
            text-align: center;
            padding: 30px;
            border-radius: 8px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }
        .header h1 {
            font-size: 3em;
            margin-bottom: 20px;
            font-weight: 700;
        }
        .header h2 {
            font-size: 1.5em;
            font-weight: 400;
            max-width: 80%;
            line-height: 1.4;
        }
        .intro {
            grid-area: intro;
            background-color: #f1f8ff;
        }
        .methods {
            grid-area: methods;
        }
        .results1 {
            grid-area: results1;
            background-color: #f7f9fc;
        }
        .results2 {
            grid-area: results2;
            background-color: #f7f9fc;
        }
        .frequency {
            grid-area: frequency;
            background-color: #f7f9fc;
        }
        .conclusion {
            grid-area: conclusion;
            background: linear-gradient(135deg, #f5f7fa, #e4ecfb);
            padding: 25px;
        }
        h2 {
            color: #2c3e50;
            font-size: 1.8em;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #4a69bd;
        }
        h3 {
            color: #34495e;
            font-size: 1.3em;
            margin: 15px 0 10px;
        }
        p, ul, ol {
            color: #333;
            line-height: 1.6;
            margin-bottom: 10px;
            font-size: 1em;
        }
        ul, ol {
            padding-left: 25px;
            margin-top: 5px;
        }
        .figure {
            background-color: white;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            text-align: center;
            border: 1px solid #e0e0e0;
        }
        .figure img {
            max-width: 100%;
            height: auto;
            margin-bottom: 10px;
        }
        .figure-caption {
            font-size: 0.9em;
            color: #666;
            text-align: left;
            margin-top: 8px;
        }
        .key-point {
            background-color: #e6f7ff;
            border-left: 4px solid #1890ff;
            padding: 10px;
            margin: 15px 0;
        }
        .highlight {
            font-weight: bold;
            color: #4a69bd;
        }
        .chart {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 15px 0;
            height: 180px;
            background-color: #f9f9f9;
            border-radius: 8px;
            border: 1px dashed #ddd;
        }
        .chart-label {
            color: #777;
            font-size: 0.9em;
        }
        .correlation-box {
            background-color: #f0f7ff;
            border-radius: 6px;
            padding: 12px;
            margin: 10px 0;
        }
        .correlation-value {
            font-size: 1.2em;
            font-weight: bold;
            color: #4a69bd;
        }
        .methods-container {
            display: flex;
            flex-direction: row;
            gap: 20px;
        }
        .methods-col {
            flex: 1;
        }
        .frequency-container {
            display: flex;
            flex-direction: row;
            gap: 20px;
        }
        .frequency-col {
            flex: 1;
        }
        .plots-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            grid-gap: 15px;
        }
    </style>
</head>
<body>
    <div class="poster">
        <div class="header section">
            <h1>Adversarial Robustness Bridges Artificial and Primate Vision</h1>
            <h2>Frequency-Driven Alignment and Attack Efficacy</h2>
        </div>

        <div class="intro section">
            <h2>Introduction</h2>
            <p>While CNNs achieve primate-level performance, their susceptibility to adversarial attacks raises questions about biological fidelity. This research investigates the connection between adversarial robustness and primate vision.</p>
            
            <div class="methods-container">
                <div class="methods-col">
                    <h3>Key Contributions</h3>
                    <ul>
                        <li><span class="highlight">Task Specificity:</span> Human vs. monkey face classification isolating core visual processing</li>
                        <li><span class="highlight">Empirical Rigor:</span> Statistical validation of alignment (ε = 0.1) and attack efficacy (ε ≥ 1)</li>
                        <li><span class="highlight">Mechanistic Insight:</span> Max-pooling introduces high-frequency gradient artifacts, suppressed in robust models</li>
                    </ul>
                </div>
                
                <div class="methods-col">
                    <div class="key-point">
                        <p><strong>Central Finding:</strong> Adversarial robustness level ε = 0.1 yields optimal alignment with primate vision, while higher robustness (ε ≥ 1) produces more effective adversarial attacks against primates.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="methods section">
            <h2>Methods</h2>
            
            <div class="methods-container">
                <div class="methods-col">
                    <h3>Dataset</h3>
                    <ul>
                        <li><strong>Human Faces:</strong> 250 front-facing, grayscale images (CFD)</li>
                        <li><strong>Monkey Faces:</strong> 250 lab-collected macaque images</li>
                        <li><strong>Test Set:</strong> 140 human / 40 monkey faces (held-out)</li>
                        <li><strong>Preprocessing:</strong> 224×224 pixels, histogram-equalized, normalized</li>
                    </ul>
                </div>
                
                <div class="methods-col">
                    <h3>Models & Training</h3>
                    <ul>
                        <li>ResNet50 pre-trained on ImageNet</li>
                        <li>Robustness Levels: ε = 0, 0.1, 1, 3, 5</li>
                        <li>PGD training: l2-norm, 10 iterations, step size 0.1</li>
                    </ul>
                    
                    <h3>Adversarial Attack Methods</h3>
                    <ul>
                        <li><strong>Gradient-Based:</strong> Model Ensemble attacks with PGD, FGSM</li>
                        <li><strong>Non-Gradient:</strong> Linear interpolation, CycleGAN</li>
                        <li><strong>Gray-Box:</strong> ResNet-101 proxy model of macaque IT responses</li>
                    </ul>
                </div>
                
                <div class="methods-col">
                    <h3>Neural & Behavioral Experiments</h3>
                    <ul>
                        <li><strong>Macaque:</strong> Recordings from ML/AM face patches (N = 3)</li>
                        <li><strong>Human:</strong> 200 participants (MTurk), 1.5s image exposure</li>
                    </ul>
                    
                    <h3>Controls & Baselines</h3>
                    <ul>
                        <li>Adversarial perturbations outperformed brown noise (+25% efficacy)</li>
                        <li>50% higher low-frequency power than Gaussian noise</li>
                        <li>Task-specific effects confirmed via rotation controls</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="results1 section">
            <h2>Model-Primate Alignment</h2>
            
            <div class="correlation-box">
                <p>ε = 0.1 models correlate strongly with:</p>
                <p>Macaque IT responses: <span class="correlation-value">r = 0.83</span> [0.79–0.87]</p>
                <p>Human behavior: <span class="correlation-value">r = 0.82</span> [0.78–0.85]</p>
            </div>
            
            <div class="plots-container">
                <div class="figure">
                    <div class="chart">
                        <p class="chart-label">[Correlation chart visualization across robustness levels]</p>
                    </div>
                    <p class="figure-caption">Figure 1A: Pearson correlations between model predictions and primate responses across robustness levels (ε).</p>
                </div>
                
                <div class="figure">
                    <div class="chart">
                        <p class="chart-label">[Neural response patterns comparison]</p>
                    </div>
                    <p class="figure-caption">Figure 1B: Comparison of neural response patterns between macaque IT and models at different robustness levels.</p>
                </div>
            </div>
            
            <div class="key-point">
                <p>Models with intermediate robustness (ε = 0.1) exhibit the strongest alignment with both human behavioral errors and macaque neural responses.</p>
            </div>
        </div>

        <div class="results2 section">
            <h2>Adversarial Attack Efficiency</h2>
            
            <div class="plots-container">
                <div class="figure">
                    <div class="chart">
                       <img src="figures/figure2A.png" alt="Attack success visualization" class="chart-label">
                    </div>
                    <p class="figure-caption">Figure 2A: Efficacy of adversarial attacks across robustness levels against primate subjects.</p>
                </div>
                
                <div class="figure">
                    <div class="chart">
                       <img src="figures/figure2B.png" alt="Attack success visualization" class="chart-label">
                    </div>
                    <p class="figure-caption">Figure 2B: Visual comparison of adversarial examples generated at different robustness levels.</p>
                </div>
            </div>
            
            <h3>Key Results</h3>
            <ul>
                <li><strong>Macaque Misclassification:</strong> ε = 5 attacks achieved 75% [70–80%] success (m2h), vs. 5% [3–7%] for ε = 0.1</li>
                <li><strong>Human Susceptibility:</strong> Gray-box attacks at ε = 5 reached 50% [45–55%] success (h2m), vs. 15% [12–18%] for ε = 0.1</li>
            </ul>
            
            <div class="key-point">
                <p>This reveals a key dissociation: alignment requires balancing invariant features, whereas attack efficacy exploits suppressed non-robust artifacts.</p>
            </div>
            
            <h3>Attack Pattern Analysis</h3>
            <p>Three distinct model patterns emerge:</p>
            <ul>
                <li>Non-robust models (ε = 0): Highly susceptible to minimal noise</li>
                <li>Moderately robust models (ε = 0.1, ε = 1): Gradual error increase with noise</li>
                <li>Highly robust models (ε = 3, ε = 5): Strong resistance requiring substantial noise</li>
            </ul>
        </div>

        <div class="frequency section">
            <h2>Frequency Analysis</h2>
            
            <div class="frequency-container">
                <div class="frequency-col">
                    <div class="figure">
                        <div class="chart">
                           <img src="figures/figure3A.png" alt="CSF model-vs-human" class="chart-label">
                        </div>
                        <p class="figure-caption">Figure 3A: Contrast sensitivity function (CSF) comparison between human perception (dotted line) and ResNet layers across robustness levels.</p>
                    </div>
                    
                    <h3>Key Findings</h3>
                    <ul>
                        <li>ε = 0 models rely on higher spatial frequencies</li>
                        <li>ε = 0.1 models achieve closest match to human CSF</li>
                        <li>ε ≥ 1 models shift toward low-frequency dependence</li>
                    </ul>
                </div>
                
                <div class="frequency-col">
                    <div class="figure">
                        <div class="chart">
                           <img src="figures/figure3B.png" alt="power distribution in fourrier CSF" class="chart-label">
                        </div>
                        <p class="figure-caption">Figure 3B: Power distribution across frequency bands in adversarial perturbations. Robust models (ε ≥ 1) show increased power in low-frequency bands.</p>
                    </div>
                    
                    <div class="key-point">
                        <p>Adversarial training suppresses high-frequency artifacts induced by max-pooling, shifting focus to perceptually relevant low-frequency features.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="conclusion section">
            <h2>Conclusion & Theoretical Implications</h2>
            
            <div class="methods-container">
                <div class="methods-col">
                    <h3>Theoretical Mechanisms</h3>
                    <ol>
                        <li><span class="highlight">ε = 0.1 Alignment:</span> Matches primate contrast sensitivity (CSF peaks &lt;10 cycles/degree), balancing invariance and discriminability</li>
                        <li><span class="highlight">ε ≥ 1 Efficacy:</span> Robust models suppress max-pooling artifacts (high-frequency noise), creating perturbations aligned with primate low-frequency bias</li>
                        <li><span class="highlight">FORGrad Dynamics:</span> Max-pooling amplifies high-frequency gradients during backpropagation (Muzellec et al., 2024), which robust models learn to ignore</li>
                    </ol>
                    
                    <div class="key-point">
                        <p>While ε = 0.1 models mirror primate decision boundaries, higher robustness (ε ≥ 1) produces perturbations dominated by low frequencies that better exploit primate CSF-driven perception.</p>
                    </div>
                </div>
                
                <div class="methods-col">
                    <p>Our findings demonstrate a nuanced relationship between adversarial robustness and biological vision:</p>
                    
                    <ul>
                        <li><strong>Alignment vs. Efficacy:</strong> Optimal alignment (ε = 0.1) differs from optimal attack efficacy (ε ≥ 1)</li>
                        <li><strong>Frequency Dynamics:</strong> Adversarial training suppresses high-frequency artifacts while prioritizing low-frequency features aligned with primate contrast sensitivity</li>
                        <li><strong>Shared Vulnerabilities:</strong> The efficacy of adversarial attacks from robust models against primates suggests fundamental shared vulnerabilities</li>
                    </ul>
                </div>
                
                <div class="methods-col">
                    <div class="key-point">
                        <p>These results extend Ilyas et al. (2019): non-robust features (high-frequency artifacts) are discarded during adversarial training, while robust features (low-frequency components) align with primate perception. This explains why ε = 0.1 models best match primate responses, whereas ε ≥ 1 models amplify low-frequency adversarial signals that exploit shared perceptual vulnerabilities.</p>
                    </div>
                    
                    <p>This work bridges computational neuroscience and AI security, offering insights into the development of more biologically plausible models and raising ethical considerations for adversarial applications to biological systems.</p>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
B
